function [y1] = dnn(x1)
%DNN neural network simulation function.
%
% Auto-generated by MATLAB, 17-May-2023 14:17:28.
% 
% [y1] = dnn(x1) takes these arguments:
%   x = 4xQ matrix, input #1
% and returns:
%   y = 1xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [-3.79770925411727;-3.98685739103758;-3.60704945724341;-3.88268403945963];
x1_step1.gain = [0.271628507479075;0.256256615215467;0.263221989367581;0.251342961695645];
x1_step1.ymin = -1;

% Layer 1
b1 = [-0.41953641101268429603;0.79360666708593530227;0.30553822813434522443;0.28373882571771363859];
IW1_1 = [0.22885314587390795382 0.13307400841301061933 1.0960579809856667577 -1.354181767163651573;1.2989262737861031471 -1.4543577114449148802 -3.2849789461202263396 3.4806381819363347851;-1.2228330246673480008 1.2369151081494527133 0.68382885975223661745 -0.68893352191392653872;2.4478055793981434718 -1.1218863602137478797 -2.457289270271481918 3.9571289148949300163];

% Layer 2
b2 = [0.31013957257504204401;-0.50030038418383226961;0.97736428090845861583;1.3596571404340667133];
LW2_1 = [0.80292187017053950893 -0.45700065020360219892 0.20627558941628615363 -0.49877108793855151614;0.032089982498598595972 -0.86258767000016078885 1.1840973661685636475 0.006958205587948105425;0.51957572016897934919 -1.0751742318177486268 1.2679462557067244788 0.65362411694193367495;0.030953673173799985813 -0.85591444839410402157 1.1775503719415234549 0.0026517301294963942226];

% Layer 3
b3 = [0.03198096525782675309;-0.13103466750532721807;-0.025661597288851506482;0.75311544166919452969];
LW3_2 = [0.022620465161685202743 -1.0675922553691312711 0.035496203164151758636 1.0043453013958321129;-0.01085564852179965456 -0.33469501439102800067 -0.13793478761423871859 -0.3765352835928070796;0.33288292799784768849 -0.67410380617855980567 -0.48712181771339746472 0.3464059297983990704;0.55550670107122768204 -0.86315341108213039512 0.77096153756777097144 -0.67803479420555179402];

% Layer 4
b4 = 0.99813910164962471594;
LW4_3 = [-1.0405317199860770749 0.30393306780545281676 -0.0051844352325778227109 0.046773788894185583387];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 2;
y1_step1.xoffset = -0.5;

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = poslin_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = poslin_apply(repmat(b2,1,Q) + LW2_1*a1);

% Layer 3
a3 = poslin_apply(repmat(b3,1,Q) + LW3_2*a2);

% Layer 4
a4 = repmat(b4,1,Q) + LW4_3*a3;

% Output 1
y1 = mapminmax_reverse(a4,y1_step1);
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Linear Positive Transfer Function
function a = poslin_apply(n,~)
  a = max(0,n);
  a(isnan(n)) = nan;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
